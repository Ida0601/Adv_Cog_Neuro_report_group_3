{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS AND DEFAULT PLOTTING PARAMETERS\n",
    "\n",
    "import mne ## MNE-Python for analysing data\n",
    "## below magic provides interactive plots in notebook\n",
    "%matplotlib widget\n",
    "from os import chdir\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt ## for basic plotting\n",
    "import matplotlib as mpl ## for setting default parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc219c",
   "metadata": {},
   "source": [
    "# 1. Define path and load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Base paths ---\n",
    "MEG_path = '/work/MEG_data/workshop_data'\n",
    "subjects_dir = '/work/freesurfer'\n",
    "behaviour_path = os.path.join(MEG_path, 'behavioural_logs')\n",
    "\n",
    "# --- List of subjects ---\n",
    "subjects = [\"0163\", \"0164\", \"0165\", \"0166\", \"0167\", \"0168\", \"0169\", \"0170\"]\n",
    "\n",
    "# dictionary to store the raw files\n",
    "raws = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop over subjects ---\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Loading subject {subj} ===\")\n",
    "\n",
    "    subj_path = os.path.join(MEG_path, subj)\n",
    "\n",
    "    # find all subfolders that start with \"2025\"\n",
    "    session_dirs = [\n",
    "        d for d in os.listdir(subj_path)\n",
    "        if d.startswith(\"2025\") and os.path.isdir(os.path.join(subj_path, d))\n",
    "    ]\n",
    "\n",
    "    if not session_dirs:\n",
    "        print(f\"No session folder starting with '2025' found for {subj}\")\n",
    "        continue\n",
    "\n",
    "    # load the data\n",
    "    session_dirs.sort()\n",
    "    session_path = os.path.join(subj_path, session_dirs[-1])\n",
    "\n",
    "    raw_path = os.path.join(session_path, \"workshop_2025_raw.fif\")\n",
    "\n",
    "    if not os.path.exists(raw_path):\n",
    "        print(f\"Raw file not found for {subj}: {raw_path}\")\n",
    "        continue\n",
    "\n",
    "    raw = mne.io.read_raw_fif(raw_path, preload=True)\n",
    "    raws[subj] = raw\n",
    "\n",
    "print(\"Finished loading all subjects!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fdbfd",
   "metadata": {},
   "source": [
    "# 3. filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d455cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj, raw in raws.items():\n",
    "    print(f\"\\n=== Filtering subject {subj} ===\")\n",
    "    raw.filter(h_freq=40, l_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b358650",
   "metadata": {},
   "source": [
    "# 4. events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_by_subj = {}\n",
    "\n",
    "for subj, raw in raws.items():\n",
    "    print(f\"Finding events for subject {subj} ...\")\n",
    "    events = mne.find_events(raw, shortest_event = 1) \n",
    "    events_by_subj[subj] = events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f4a63",
   "metadata": {},
   "source": [
    "# 5. link the events with the behavioural logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf47c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_by_subj = {}\n",
    "\n",
    "# --- Loop over subjects ---\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Loading behavioural data for subject {subj} ===\")\n",
    "\n",
    "    # find file that starts with the subject ID and 2025\n",
    "    for file in os.listdir(behaviour_path):\n",
    "        if file.startswith(f\"{subj}_2025\") and file.endswith(\"_experiment_data.csv\"):\n",
    "            behaviour_file = os.path.join(behaviour_path, file)\n",
    "            break\n",
    "    else:\n",
    "        print(f\" No behavioural file found for {subj}\")\n",
    "        continue\n",
    "\n",
    "    behaviour = pd.read_csv(behaviour_file, index_col=False)\n",
    "    behaviour['PAS_score'] = behaviour['subjective_response'].astype(str) + \"00\"\n",
    "    behaviour_by_subj[subj] = behaviour\n",
    "\n",
    "    print(behaviour.columns)\n",
    "    print(behaviour)\n",
    "\n",
    "print(\"Finished loading behavioural data for all subjects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d06611",
   "metadata": {},
   "source": [
    "# 6. Only keep stimulus events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf508b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop over subjects ---\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Applying behavioural PAS labels for subject {subj} ===\")\n",
    "\n",
    "    # skip if we don't have behaviour for this subject\n",
    "    if subj not in behaviour_by_subj:\n",
    "        print(f\" No behavioural data for {subj}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    events = events_by_subj[subj]\n",
    "    behaviour = behaviour_by_subj[subj]\n",
    "\n",
    "    target_indices = np.isin(events[:, 2], [1, 3]) # i changed this bit\n",
    "    events = events[target_indices, :] \n",
    "    \n",
    "\n",
    "    if len(events) == 0:\n",
    "        print(f\" No stimulus events found for {subj}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    n_behav = len(behaviour)\n",
    "    n_events = len(events)\n",
    "    if n_behav != n_events:\n",
    "        print(f\" {subj}: mismatch (events={n_events}, behaviour={n_behav}), trimming to shortest.\")\n",
    "        min_len = min(n_behav, n_events)\n",
    "        events = events[:min_len, :]\n",
    "        behaviour = behaviour.iloc[:min_len]\n",
    "\n",
    "    events[:, 2] = behaviour[\"PAS_score\"].astype(int).to_numpy()\n",
    "    events_by_subj[subj] = events\n",
    "\n",
    "print(\"\\n Finished applying PAS labels to all subjects!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e146572",
   "metadata": {},
   "source": [
    "# 7. Merge pas 4 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85112e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop over subjects ---\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Summarizing and merging PAS scores for subject {subj} ===\")\n",
    "\n",
    "    events = events_by_subj[subj]\n",
    "\n",
    "    # merge PAS 4 (400) with PAS 3 (300)\n",
    "    events[events[:, 2] == 400, 2] = 300\n",
    "\n",
    "    # update dictionary\n",
    "    events_by_subj[subj] = events\n",
    "\n",
    "     # show counts before merge\n",
    "    unique, counts = np.unique(events[:, 2], return_counts=True)\n",
    "    print(np.asarray((unique, counts)).T)\n",
    "\n",
    "\n",
    "print(\"Finished summarizing and merging PAS scores for all subjects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae21298",
   "metadata": {},
   "source": [
    "# Only keep Pas 1 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861756a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create filtered event sets: PAS 200 vs 300 ---\n",
    "events_2vs3_by_subj = {}\n",
    "\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Filtering PAS 100 vs 200 for subject {subj} ===\")\n",
    "\n",
    "    if subj not in events_by_subj:\n",
    "        print(f\" No events found for {subj}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    events = events_by_subj[subj]\n",
    "\n",
    "    # keep only PAS 100 and 300\n",
    "    mask = np.isin(events[:, 2], [200, 300])\n",
    "    events_2vs3 = events[mask]\n",
    "\n",
    "    if len(events_2vs3) == 0:\n",
    "        print(f\" No PAS 100/200 trials for {subj}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    events_2vs3_by_subj[subj] = events_2vs3\n",
    "    print(f\" {subj}: kept {len(events_2vs3)} trials (PAS 100/200 only)\")\n",
    "\n",
    "print(\"\\n Finished filtering PAS 100 vs 100 for all subjects!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcdfb0",
   "metadata": {},
   "source": [
    "# 8. Creating the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8885ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop over subjects --- (skipping 0164)\n",
    "for subj in subjects:\n",
    "\n",
    "    print(f\"\\n=== Creating epochs for subject {subj} ===\")\n",
    "\n",
    "    raw = raws[subj]\n",
    "    events = events_2vs3_by_subj[subj]\n",
    "\n",
    "    # create dict with event ID mapped to desired labels\n",
    "    event_ids = {\"PAS2\": 200,\n",
    "                 \"PAS3\": 300}\n",
    "\n",
    "    # define input to epoch function\n",
    "    tmin = -0.200\n",
    "    tmax = 0.550\n",
    "    baseline = (-0.200, 0)\n",
    "    reject = {'eog': 250e-6}\n",
    "\n",
    "    # epoch data with EOG rejection\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events=events,\n",
    "                        event_id=event_ids,\n",
    "                        tmin=tmin,\n",
    "                        tmax=tmax,\n",
    "                        baseline=baseline,\n",
    "                        preload=True,\n",
    "                        reject=reject,\n",
    "                        on_missing='ignore')\n",
    "\n",
    "    # store both in dictionaries if you want to keep them\n",
    "    if 'epochs_by_subj' not in locals():\n",
    "        epochs_by_subj = {}\n",
    "\n",
    "    epochs_by_subj[subj] = epochs\n",
    "\n",
    "print(\"\\n Finished creating epochs for all subjects (skipped 0164).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c084d",
   "metadata": {},
   "source": [
    "# Force Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ebdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Force-balance PAS1 vs PAS3 per subject ---\n",
    "\n",
    "epochs_balanced_by_subj = {}\n",
    "\n",
    "for subj, ep in epochs_by_subj.items():\n",
    "    print(f\"\\n=== Balancing epochs for subject {subj} ===\")\n",
    "\n",
    "    # get condition names, e.g. [\"PAS1\", \"PAS3\"]\n",
    "    conds = list(ep.event_id.keys())\n",
    "    if len(conds) != 2:\n",
    "        print(f\" {subj}: Expected 2 conditions, found {conds}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # split epochs into the two PAS conditions\n",
    "    ep_list = [ep[conds[0]], ep[conds[1]]]\n",
    "\n",
    "    # balance the number of trials\n",
    "    mne.epochs.equalize_epoch_counts(ep_list)\n",
    "\n",
    "    # merge back together\n",
    "    ep_balanced = mne.concatenate_epochs(ep_list)\n",
    "    epochs_balanced_by_subj[subj] = ep_balanced\n",
    "\n",
    "    print(f\" {subj}: kept {len(ep_list[0])} epochs per condition (total {len(ep_balanced)})\")\n",
    "\n",
    "print(\"\\n Finished balancing PAS1 vs PAS3 for all subjects!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7d0ed",
   "metadata": {},
   "source": [
    "# Multinomial regression in sensor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for logistic regression \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- config ---\n",
    "subjects_use = subjects                     # use all subjects you kept\n",
    "picks = \"meg\"\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2002)\n",
    "\n",
    "logr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, class_weight='balanced', solver='lbfgs')\n",
    ")\n",
    "\n",
    "scores_by_subj = {}  # {subj: scores_t}\n",
    "times = None\n",
    "\n",
    "for subj in subjects_use:\n",
    "    print(f\"\\n=== Decoding PAS200 vs PAS300 for {subj} ===\")\n",
    "\n",
    "    # pick MEG channels\n",
    "    e = epochs_balanced_by_subj[subj].copy().pick(picks)\n",
    "\n",
    "    X = e.get_data()         # shape: (trials, sensors, time)\n",
    "    y = e.events[:, 2]       # contains only 200 & 300 now\n",
    "\n",
    "    # recode labels: 200 -> 0, 300 -> 1\n",
    "    y_bin = (y == 300).astype(int)\n",
    "\n",
    "    if times is None:\n",
    "        times = e.times\n",
    "    n_times = X.shape[2]\n",
    "\n",
    "    scores_t = np.zeros(n_times)\n",
    "\n",
    "    for t in range(n_times):\n",
    "        print(f\"{subj}: time {t+1}/{n_times}\", end=\"\\r\")\n",
    "        Xt = X[:, :, t]   # (trials, sensors)\n",
    "        scores_t[t] = cross_val_score(logr, Xt, y_bin, cv=cv, n_jobs=-1).mean()\n",
    "\n",
    "    scores_by_subj[subj] = scores_t\n",
    "    print()  # new line after subject\n",
    "\n",
    "# --- compute group mean curve ---\n",
    "S = np.vstack([scores_by_subj[subj] for subj in scores_by_subj])\n",
    "group_mean = S.mean(axis=0)\n",
    "\n",
    "# --- plot ---\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, label=f\"Chance ({chance:.2f})\")\n",
    "plt.plot(times, group_mean, label=\"PAS200 vs PAS300\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Decoding Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- plot ---\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, label=f\"Chance ({chance:.2f})\")\n",
    "plt.plot(times, group_mean, label=\"PAS200 vs PAS300\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Decoding Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3592bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading results for later use:\n",
    "S_2vs3 = np.load(\"group_scores_2vs3.npy\")\n",
    "\n",
    "# Load the .npz file\n",
    "data_2vs3 = np.load(\"group_mean_results_2vs3.npz\")\n",
    "\n",
    "# Access the arrays\n",
    "group_mean_2vs3 = data_2vs3[\"mean\"]\n",
    "times = data_2vs3[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc085c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "# S = subjects x times\n",
    "T_obs_2vs3, clusters_2vs3, cluster_p_values_2vs3, H0_2vs3 = permutation_cluster_1samp_test(\n",
    "    S_2vs3 - 0.5,  # subtract chance\n",
    "    n_permutations=1000,\n",
    "    tail=1,  # test above chance\n",
    "    threshold=None,  # t-threshold can be auto-determined\n",
    "    out_type='mask'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot chance line\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, color='k', label=f\"Chance ({chance:.2f})\")\n",
    "\n",
    "# Plot group mean decoding\n",
    "plt.plot(times, group_mean_2vs3, label=\"PAS200 vs PAS300\", color='b')\n",
    "\n",
    "# Shade significant clusters\n",
    "for i_c, c in enumerate(clusters_2vs3):\n",
    "    if cluster_p_values_2vs3[i_c] < 0.05:\n",
    "        # Convert the slice/boolean mask to actual time points\n",
    "        if isinstance(c, tuple):  # MNE may return a tuple with a slice\n",
    "            cluster_indices = np.arange(*c[0].indices(len(times)))\n",
    "        else:  # boolean array\n",
    "            cluster_indices = np.where(c)[0]\n",
    "\n",
    "        # Shade the cluster\n",
    "        plt.axvspan(times[cluster_indices[0]], times[cluster_indices[-1]], color='red', alpha=0.3)\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Balanced Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading results for later use:\n",
    "S_1vs3 = np.load(\"group_scores_1vs3.npy\")\n",
    "\n",
    "# Load the .npz file\n",
    "data_1vs3 = np.load(\"group_mean_results_1vs3.npz\")\n",
    "\n",
    "# Access the arrays\n",
    "group_mean_1vs3 = data_1vs3[\"mean\"]\n",
    "times = data_1vs3[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9561cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "# S = subjects x times\n",
    "T_obs_1vs3, clusters_1vs3, cluster_p_values_1vs3, H0_1vs3 = permutation_cluster_1samp_test(\n",
    "    S_1vs3 - 0.5,  # subtract chance\n",
    "    n_permutations=1000,\n",
    "    tail=1,  # test above chance\n",
    "    threshold=None,  # t-threshold can be auto-determined\n",
    "    out_type='mask'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot chance line\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, color='k', label=f\"Chance ({chance:.2f})\")\n",
    "\n",
    "# Plot group mean decoding\n",
    "plt.plot(times, group_mean_1vs3, label=\"PAS100 vs PAS300\", color='b')\n",
    "\n",
    "# Shade significant clusters\n",
    "for i_c, c in enumerate(clusters_1vs3):\n",
    "    if cluster_p_values_1vs3[i_c] < 0.05:\n",
    "        # Convert the slice/boolean mask to actual time points\n",
    "        if isinstance(c, tuple):  # MNE may return a tuple with a slice\n",
    "            cluster_indices = np.arange(*c[0].indices(len(times)))\n",
    "        else:  # boolean array\n",
    "            cluster_indices = np.where(c)[0]\n",
    "\n",
    "        # Shade the cluster\n",
    "        plt.axvspan(times[cluster_indices[0]], times[cluster_indices[-1]], color='red', alpha=0.3)\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Balanced Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading results for later use:\n",
    "S_1vs2 = np.load(\"group_scores_1vs2.npy\")\n",
    "\n",
    "# Load the .npz file\n",
    "data_1vs2 = np.load(\"group_mean_results_1vs2.npz\")\n",
    "\n",
    "# Access the arrays\n",
    "group_mean_1vs2 = data_1vs2[\"mean\"]\n",
    "times = data_1vs2[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c906ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "# S = subjects x times\n",
    "T_obs_1vs2, clusters_1vs2, cluster_p_values_1vs2, H0_1vs2 = permutation_cluster_1samp_test(\n",
    "    S_1vs2 - 0.5,  # subtract chance\n",
    "    n_permutations=1000,\n",
    "    tail=1,  # test above chance\n",
    "    threshold=None,  # t-threshold can be auto-determined\n",
    "    out_type='mask'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot chance line\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, color='k', label=f\"Chance ({chance:.2f})\")\n",
    "\n",
    "# Plot group mean decoding\n",
    "plt.plot(times, group_mean_1vs2, label=\"PAS100 vs PAS200\", color='b')\n",
    "\n",
    "# Shade significant clusters\n",
    "for i_c, c in enumerate(clusters_1vs2):\n",
    "    if cluster_p_values_1vs2[i_c] < 0.05:\n",
    "        # Convert the slice/boolean mask to actual time points\n",
    "        if isinstance(c, tuple):  # MNE may return a tuple with a slice\n",
    "            cluster_indices = np.arange(*c[0].indices(len(times)))\n",
    "        else:  # boolean array\n",
    "            cluster_indices = np.where(c)[0]\n",
    "\n",
    "        # Shade the cluster\n",
    "        plt.axvspan(times[cluster_indices[0]], times[cluster_indices[-1]], color='red', alpha=0.3)\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Balanced Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example for one subject\n",
    "times = epochs_balanced_by_subj[\"0163\"].times  # array of time points in seconds\n",
    "\n",
    "# Loop over all clusters\n",
    "significant_clusters = []\n",
    "\n",
    "for i_c, c in enumerate(clusters_2vs3):\n",
    "    p_val = cluster_p_values_2vs3[i_c]\n",
    "    if p_val < 0.05:  # significant cluster\n",
    "        # Convert slice or boolean mask to indices\n",
    "        if isinstance(c, tuple):\n",
    "            cluster_indices = np.arange(*c[0].indices(len(times)))\n",
    "        else:  # boolean array\n",
    "            cluster_indices = np.where(c)[0]\n",
    "        \n",
    "        # Map indices to time in ms\n",
    "        cluster_times_ms = times[cluster_indices] * 1000\n",
    "        start_ms = cluster_times_ms[0]\n",
    "        end_ms = cluster_times_ms[-1]\n",
    "        \n",
    "        significant_clusters.append({\n",
    "            \"cluster_index\": i_c,\n",
    "            \"p_value\": p_val,\n",
    "            \"time_range_ms\": (start_ms, end_ms)\n",
    "        })\n",
    "\n",
    "# Print results\n",
    "for cl in significant_clusters:\n",
    "    print(f\"Cluster {cl['cluster_index']} (p={cl['p_value']:.3f}) \"\n",
    "          f\"time range: {cl['time_range_ms'][0]:.1f}â€“{cl['time_range_ms'][1]:.1f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chance = 0.5\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot chance line\n",
    "plt.axhline(chance, linestyle=\"--\", linewidth=1, color='k', label=f\"Chance ({chance:.2f})\")\n",
    "\n",
    "# Plot multiple group means\n",
    "plt.plot(times, group_mean_1vs3, label=\"PAS-1 vs PAS-3\", color='#1B3A6F')  # navy\n",
    "plt.plot(times, group_mean_2vs3, label=\"PAS-2 vs PAS-3\", color='#2878B5')  # medium blue\n",
    "plt.plot(times, group_mean_1vs2, label=\"PAS-1 vs PAS-2\", color='#76B7E5')  # sky blue\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Decoding Accuracy\")\n",
    "plt.title(\"Time-resolved PAS decoding (sensor space)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a01ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the index of the peak mean\n",
    "peak_idx = np.argmax(group_mean_2vs3)\n",
    "\n",
    "# Get the peak value\n",
    "peak_value = group_mean_2vs3[peak_idx]\n",
    "\n",
    "# Get the corresponding time (assuming you have a 'times' array)\n",
    "peak_time = times[peak_idx]*1000\n",
    "\n",
    "print(f\"Peak mean decoding: {peak_value:.3f} at {peak_time:.1f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
